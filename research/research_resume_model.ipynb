{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "class Address(BaseModel):\n",
    "    street: Optional[str]\n",
    "    city: Optional[str]\n",
    "    state: Optional[str]\n",
    "    zip_code: Optional[str]\n",
    "    country: Optional[str]\n",
    "class BasicInfo(BaseModel):\n",
    "    full_name: str\n",
    "    current_title: Optional[str]\n",
    "    gender: Optional[str]\n",
    "    date_of_birth: Optional[str]\n",
    "    nationality: Optional[str]\n",
    "class ContactInfo(BaseModel):\n",
    "    email: Optional[str]\n",
    "    phone: Optional[str]\n",
    "    address: Optional[Address]\n",
    "    linkedin: Optional[str]\n",
    "    github: Optional[str]\n",
    "    portfolio: Optional[str]\n",
    "class Skill(BaseModel):\n",
    "    skill_name: str\n",
    "    proficiency: Optional[str]\n",
    "    category: Optional[str]\n",
    "    years_of_experience: Optional[int]\n",
    "class Education(BaseModel):\n",
    "    degree: str\n",
    "    field: Optional[str]\n",
    "    institution: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    grade: Optional[str]\n",
    "    location: Optional[str]\n",
    "    courses: List[str]\n",
    "class Experience(BaseModel):\n",
    "    job_title: str\n",
    "    company: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    employment_type: Optional[str]\n",
    "    location: Optional[str]\n",
    "    responsibilities: List[str]\n",
    "    skills_used: List[str]\n",
    "class Project(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str]\n",
    "    technologies: List[str]\n",
    "    role: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    link: Optional[str]\n",
    "class Certification(BaseModel):\n",
    "    title: str\n",
    "    issuer: Optional[str]\n",
    "    issue_date: Optional[str]\n",
    "    expiration_date: Optional[str]\n",
    "    credential_id: Optional[str]\n",
    "    url: Optional[str]\n",
    "class Publication(BaseModel):\n",
    "    title: str\n",
    "    journal: Optional[str]\n",
    "    authors: Optional[List[str]]\n",
    "    year: Optional[int]\n",
    "    doi: Optional[str]\n",
    "    url: Optional[str]\n",
    "class Language(BaseModel):\n",
    "    language: str\n",
    "    proficiency: Optional[str]\n",
    "class VolunteerExperience(BaseModel):\n",
    "    role: str\n",
    "    organization: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    description: Optional[str]\n",
    "class Award(BaseModel):\n",
    "    title: str\n",
    "    issuer: Optional[str]\n",
    "    date: Optional[str]\n",
    "    description: Optional[str]\n",
    "class Link(BaseModel):\n",
    "    label: Optional[str]\n",
    "    url: Optional[str]\n",
    "class Resume(BaseModel):\n",
    "    basic_info: BasicInfo\n",
    "    contact_info: ContactInfo\n",
    "    summary: Optional[str]\n",
    "    skills: List[Skill]\n",
    "    education: List[Education]\n",
    "    experience: List[Experience]\n",
    "    projects: List[Project]\n",
    "    certifications: Optional[List[Certification]] = []\n",
    "    publications: Optional[List[Publication]] = []\n",
    "    languages: List[Language]\n",
    "    interests: Optional[List[str]] = []\n",
    "    volunteer_experience: Optional[List[VolunteerExperience]] = []\n",
    "    awards: Optional[List[Award]] = []\n",
    "    links: Optional[List[Link]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, HttpUrl, Field\n",
    "from uuid import UUID\n",
    "from enum import Enum\n",
    "\n",
    "class EmploymentType(str, Enum):\n",
    "    full_time = \"full_time\"\n",
    "    part_time = \"part_time\"\n",
    "    contract = \"contract\"\n",
    "    temporary = \"temporary\"\n",
    "    internship = \"internship\"\n",
    "    freelance = \"freelance\"\n",
    "class JobLevel(str, Enum):\n",
    "    entry = \"entry\"\n",
    "    mid = \"mid\"\n",
    "    senior = \"senior\"\n",
    "    lead = \"lead\"\n",
    "    manager = \"manager\"\n",
    "    director = \"director\"\n",
    "    executive = \"executive\"\n",
    "class SalaryPeriod(str, Enum):\n",
    "    hour = \"hour\"\n",
    "    day = \"day\"\n",
    "    week = \"week\"\n",
    "    month = \"month\"\n",
    "    year = \"year\"\n",
    "class EducationLevel(str, Enum):\n",
    "    high_school = \"high_school\"\n",
    "    associate = \"associate\"\n",
    "    bachelor = \"bachelor\"\n",
    "    master = \"master\"\n",
    "    phd = \"phd\"\n",
    "    other = \"other\"\n",
    "class LanguageProficiency(str, Enum):\n",
    "    basic = \"basic\"\n",
    "    conversational = \"conversational\"\n",
    "    fluent = \"fluent\"\n",
    "    native = \"native\"\n",
    "class Location(BaseModel):\n",
    "    city: Optional[str]\n",
    "    state: Optional[str]\n",
    "    country: Optional[str]\n",
    "    zip_code: Optional[str]\n",
    "    remote: Optional[bool]\n",
    "class Salary(BaseModel):\n",
    "    currency: Optional[str]\n",
    "    min: Optional[float]\n",
    "    max: Optional[float]\n",
    "    period: Optional[SalaryPeriod]\n",
    "    is_estimated: Optional[bool]\n",
    "class EducationRequirement(BaseModel):\n",
    "    degree: Optional[str]\n",
    "    field_of_study: Optional[str]\n",
    "    level: Optional[EducationLevel]\n",
    "class ExperienceYears(BaseModel):\n",
    "    min: Optional[float]\n",
    "    max: Optional[float]\n",
    "class Qualifications(BaseModel):\n",
    "    education: Optional[List[EducationRequirement]] = []\n",
    "    experience_years: Optional[ExperienceYears]\n",
    "    certifications: Optional[List[str]] = []\n",
    "class Skills(BaseModel):\n",
    "    mandatory: Optional[List[str]] = []\n",
    "    optional: Optional[List[str]] = []\n",
    "    tools: Optional[List[str]] = []\n",
    "class LanguageRequirement(BaseModel):\n",
    "    language: str\n",
    "    proficiency: Optional[LanguageProficiency]\n",
    "class CompanyInfo(BaseModel):\n",
    "    name: Optional[str]\n",
    "    website: Optional[str]\n",
    "    description: Optional[str]\n",
    "class Analytics(BaseModel):\n",
    "    views: Optional[int]\n",
    "    applications: Optional[int]\n",
    "class Metadata(BaseModel):\n",
    "    created_at: Optional[str]\n",
    "    updated_at: Optional[str]\n",
    "    created_by_user_id: Optional[str]\n",
    "    source: Optional[str]\n",
    "class JobDescription(BaseModel):\n",
    "    job_id: UUID\n",
    "    title: str\n",
    "    description: Optional[str]\n",
    "    summary: Optional[str]\n",
    "    employment_type: Optional[EmploymentType]\n",
    "    industry: Optional[str]\n",
    "    department: Optional[str]\n",
    "    function: Optional[str]\n",
    "    job_level: Optional[JobLevel]\n",
    "    locations: Optional[List[Location]] = []\n",
    "    is_remote: Optional[bool]\n",
    "    is_hybrid: Optional[bool]\n",
    "    is_onsite: Optional[bool]\n",
    "    application_url: Optional[str]  # Can change to HttpUrl if strictly URL\n",
    "    posting_date: Optional[str]\n",
    "    closing_date: Optional[str]\n",
    "    salary: Optional[Salary]\n",
    "    benefits: Optional[List[str]] = []\n",
    "    qualifications: Optional[Qualifications]\n",
    "    skills: Optional[Skills]\n",
    "    languages: Optional[List[LanguageRequirement]] = []\n",
    "    responsibilities: Optional[List[str]] = []\n",
    "    requirements: Optional[List[str]] = []\n",
    "    nice_to_have: Optional[List[str]] = []\n",
    "    company: Optional[CompanyInfo]\n",
    "    analytics: Optional[Analytics]\n",
    "    metadata: Optional[Metadata]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import re\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MongoDBManager:\n",
    "    def __init__(self, connection_string, db_name):\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client[db_name]\n",
    "        self.jobs_collection = self.db['jobs']\n",
    "        self.resumes_collection = self.db['parsed_resumes']\n",
    "        self.applications_collection = self.db['application_collections']  # Added applications collection\n",
    "    \n",
    "    def get_all_jobs(self):\n",
    "        return list(self.jobs_collection.find({}))\n",
    "    \n",
    "    def get_all_resumes(self):\n",
    "        return list(self.resumes_collection.find({}))\n",
    "    \n",
    "    def get_job_by_id(self, job_id):\n",
    "        try:\n",
    "            return self.jobs_collection.find_one({\"_id\": ObjectId(job_id)})\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def get_resume_by_id(self, resume_id):\n",
    "        try:\n",
    "            return self.resumes_collection.find_one({\"_id\": ObjectId(resume_id)})\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def get_job_applicants(self, job_id):\n",
    "        \"\"\"Get all applicants for a specific job\"\"\"\n",
    "        try:\n",
    "            applications = list(self.applications_collection.find({\"job_id\": ObjectId(job_id)}))\n",
    "            return applications\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching applicants for job {job_id}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_user_by_id(self, user_id):\n",
    "        \"\"\"Get user information by user_id\"\"\"\n",
    "        try:\n",
    "            return self.db['users'].find_one({\"_id\": ObjectId(user_id)})\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def get_job_by_recruiter_id(self, recruiter_id):\n",
    "        try:\n",
    "            return list(self.jobs_collection.find({\"recruiter_id\": ObjectId(recruiter_id)}))\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def get_resume_by_user_id(self, user_id):\n",
    "        try:\n",
    "            return list(self.resumes_collection.find({\"user_id\": ObjectId(user_id)}))\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def close(self):\n",
    "        self.client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the manager\n",
    "manager = MongoDBManager(\"mongodb://localhost:27017/\", \"resume_parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MatchScore:\n",
    "    \"\"\"Class to hold matching scores and explanations\"\"\"\n",
    "    def __init__(self, score: float = 0.0, max_score: float = 1.0, explanation: str = \"\"):\n",
    "        self.score = score\n",
    "        self.max_score = max_score\n",
    "        self.normalized_score = score / max_score if max_score > 0 else 0.0\n",
    "        self.explanation = explanation\n",
    "\n",
    "class EducationMatcher:\n",
    "    \"\"\"Handles education-based matching between resume and job description\"\"\"\n",
    "    # Degree hierarchy mapping (higher number = higher level)\n",
    "    DEGREE_HIERARCHY = {\n",
    "        'high_school': 1, 'diploma': 1, 'certificate': 1,\n",
    "        'associate': 2, 'associates': 2,\n",
    "        'bachelor': 3, 'bachelors': 3, 'bsc': 3, 'ba': 3, 'btech': 3, 'be': 3,\n",
    "        'master': 4, 'masters': 4, 'msc': 4, 'ma': 4, 'mtech': 4, 'mba': 4,\n",
    "        'phd': 5, 'doctorate': 5, 'doctoral': 5\n",
    "    }\n",
    "    \n",
    "    # Grade conversion to 4.0 scale (approximate)\n",
    "    GRADE_CONVERSIONS = {\n",
    "        'a+': 4.0, 'a': 3.7, 'a-': 3.3,\n",
    "        'b+': 3.0, 'b': 2.7, 'b-': 2.3,\n",
    "        'c+': 2.0, 'c': 1.7, 'c-': 1.3,\n",
    "        'd': 1.0, 'f': 0.0\n",
    "    }\n",
    "    \n",
    "    # Field similarity groups (can be expanded with embeddings)\n",
    "    FIELD_SIMILARITY = {\n",
    "        'computer_science': ['computer science', 'cs', 'software engineering', 'information technology', 'it', 'ai', 'artificial intelligence', 'intelligence'],\n",
    "        'engineering': ['engineering', 'mechanical', 'electrical', 'civil', 'chemical'],\n",
    "        'business': ['business', 'mba', 'management', 'finance', 'marketing', 'economics'],\n",
    "        'science': ['physics', 'chemistry', 'biology', 'mathematics', 'statistics'],\n",
    "        'design': ['design', 'graphic design', 'ui/ux', 'visual design', 'product design']\n",
    "    }\n",
    "    \n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_text(self, text: str):\n",
    "        return self.model.encode(text, normalize_embeddings=True, show_progress_bar=False)\n",
    "    \n",
    "    def normalize_degree(self, degree: str) -> str:\n",
    "        \"\"\"Normalize degree name for comparison\"\"\"\n",
    "        if not degree:\n",
    "            return \"\"\n",
    "        degree_clean = re.sub(r'[^\\w\\s]', '', degree.lower().strip())\n",
    "        # Extract key degree terms\n",
    "        for key in self.DEGREE_HIERARCHY:\n",
    "            if key in degree_clean:\n",
    "                return key\n",
    "        return degree_clean\n",
    "    \n",
    "    def normalize_field(self, field: str) -> str:\n",
    "        \"\"\"Normalize field of study for comparison\"\"\"\n",
    "        if not field:\n",
    "            return \"\"\n",
    "        return re.sub(r'[^\\w\\s]', '', field.lower().strip())\n",
    "    \n",
    "    def get_degree_level(self, degree: str) -> int:\n",
    "        \"\"\"Get numeric level of degree\"\"\"\n",
    "        normalized = self.normalize_degree(degree)\n",
    "        return self.DEGREE_HIERARCHY.get(normalized, 0)\n",
    "    \n",
    "    def convert_grade_to_gpa(self, grade: str) -> Optional[float]:\n",
    "        \"\"\"Convert various grade formats to 4.0 GPA scale\"\"\"\n",
    "        if not grade:\n",
    "            return None\n",
    "            \n",
    "        grade_clean = grade.lower().strip()\n",
    "        \n",
    "        # Direct GPA (e.g., \"3.5\", \"3.5/4.0\")\n",
    "        gpa_match = re.search(r'(\\d+\\.?\\d*)\\s*(?:/\\s*(\\d+\\.?\\d*))?', grade_clean)\n",
    "        if gpa_match:\n",
    "            gpa = float(gpa_match.group(1))\n",
    "            scale = float(gpa_match.group(2)) if gpa_match.group(2) else 4.0\n",
    "            return min(4.0, (gpa / scale) * 4.0)\n",
    "        \n",
    "        # Letter grades\n",
    "        if grade_clean in self.GRADE_CONVERSIONS:\n",
    "            return self.GRADE_CONVERSIONS[grade_clean]\n",
    "        \n",
    "        # Percentage (assuming 90+ = A, 80+ = B, etc.)\n",
    "        percentage_match = re.search(r'(\\d+)%?', grade_clean)\n",
    "        if percentage_match:\n",
    "            percentage = float(percentage_match.group(1))\n",
    "            if percentage >= 90:\n",
    "                return 4.0\n",
    "            elif percentage >= 80:\n",
    "                return 3.0\n",
    "            elif percentage >= 70:\n",
    "                return 2.0\n",
    "            elif percentage >= 60:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.5\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def calculate_field_similarity(self, resume_field: str, required_field: str) -> float:\n",
    "        \"\"\"Calculate semantic similarity between fields of study\"\"\"\n",
    "        if not resume_field or not required_field:\n",
    "            return 0.0\n",
    "\n",
    "        resume_field_norm = self.normalize_field(resume_field)\n",
    "        required_field_norm = self.normalize_field(required_field)\n",
    "\n",
    "        # Exact match\n",
    "        if resume_field_norm == required_field_norm:\n",
    "            return 1.0\n",
    "\n",
    "        # Group similarity\n",
    "        group_score = 0.0\n",
    "        for group, fields in self.FIELD_SIMILARITY.items():\n",
    "            resume_in_group = any(field in resume_field_norm for field in fields)\n",
    "            required_in_group = any(field in required_field_norm for field in fields)\n",
    "            if resume_in_group and required_in_group:\n",
    "                group_score = 0.8\n",
    "                break\n",
    "\n",
    "        # Partial word overlap (Jaccard)\n",
    "        resume_words = set(resume_field_norm.split())\n",
    "        required_words = set(required_field_norm.split())\n",
    "        intersection = resume_words & required_words\n",
    "        union = resume_words | required_words\n",
    "        overlap_score = (len(intersection) / len(union)) * 0.6 if union else 0.0\n",
    "\n",
    "        # Embedding similarity using SentenceTransformer\n",
    "        try:\n",
    "            resume_vec = self.embed_text(resume_field_norm)\n",
    "            required_vec = self.embed_text(required_field_norm)\n",
    "            emb_score = float(cosine_similarity([resume_vec], [required_vec])[0][0])\n",
    "        except Exception:\n",
    "            emb_score = 0.0\n",
    "\n",
    "        # Combine scores: you can tune these weights\n",
    "        total_score = (group_score * 0.5) + (overlap_score * 0.2) + (emb_score * 0.4)\n",
    "        return min(total_score, 0.99)  # never return 1.0 unless exact match\n",
    "\n",
    "    def match_education(self, resume_education: List, job_education: List) -> MatchScore:\n",
    "        \"\"\"\n",
    "        Match education requirements between resume and job description\n",
    "        \n",
    "        Scoring Rules:\n",
    "        1. Degree Level Match (40 points):\n",
    "           - Exact match: 40 points\n",
    "           - Higher degree: 35 points\n",
    "           - One level lower: 25 points\n",
    "           - Two+ levels lower: 10 points\n",
    "           - No relevant degree: 0 points\n",
    "        \n",
    "        2. Field Relevance (35 points):\n",
    "           - Exact field match: 35 points\n",
    "           - Closely related: 28 points\n",
    "           - Somewhat related: 15 points\n",
    "           - Unrelated: 5 points\n",
    "        \n",
    "        3. Grade Quality (25 points):\n",
    "           - GPA >= 3.5: 25 points\n",
    "           - GPA >= 3.0: 20 points\n",
    "           - GPA >= 2.5: 15 points\n",
    "           - GPA < 2.5: 10 points\n",
    "           - No grade info: 12 points (neutral)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not job_education:\n",
    "            return MatchScore(80.0, 100.0, \"No specific education requirements\")\n",
    "        \n",
    "        if not resume_education:\n",
    "            return MatchScore(0.0, 100.0, \"No education information in resume\")\n",
    "        \n",
    "        best_match_score = 0.0\n",
    "        best_explanation = \"\"\n",
    "        \n",
    "        for job_req in job_education:\n",
    "            for resume_edu in resume_education:\n",
    "                current_score = 0.0\n",
    "                explanations = []\n",
    "                \n",
    "                # 1. Degree Level Matching (40 points)\n",
    "                resume_level = self.get_degree_level(resume_edu.degree)\n",
    "                if job_req.degree:\n",
    "                    required_level = self.get_degree_level(job_req.degree)\n",
    "                elif job_req.level:\n",
    "                    required_level = self.DEGREE_HIERARCHY.get(job_req.level.value, 0)\n",
    "                else:\n",
    "                    required_level = 3  # Default to bachelor's if not specified\n",
    "                \n",
    "                if resume_level == required_level:\n",
    "                    current_score += 40\n",
    "                    explanations.append(f\"Exact degree level match ({resume_edu.degree})\")\n",
    "                elif resume_level > required_level:\n",
    "                    current_score += 35\n",
    "                    explanations.append(f\"Higher degree than required ({resume_edu.degree})\")\n",
    "                elif resume_level == required_level - 1:\n",
    "                    current_score += 25\n",
    "                    explanations.append(f\"One level below required degree\")\n",
    "                elif resume_level > 0:\n",
    "                    current_score += 10\n",
    "                    explanations.append(f\"Lower degree level\")\n",
    "                else:\n",
    "                    explanations.append(f\"No recognized degree level\")\n",
    "                \n",
    "                # 2. Field Relevance (35 points)\n",
    "                field_similarity = 0.0\n",
    "                if job_req.field_of_study and resume_edu.field:\n",
    "                    field_similarity = self.calculate_field_similarity(\n",
    "                        resume_edu.field, job_req.field_of_study\n",
    "                    )\n",
    "                elif not job_req.field_of_study:\n",
    "                    field_similarity = 0.8  # No specific field required\n",
    "                \n",
    "                field_score = field_similarity * 35\n",
    "                current_score += field_score\n",
    "                \n",
    "                if field_similarity >= 0.9:\n",
    "                    explanations.append(\"Excellent field match\")\n",
    "                elif field_similarity >= 0.7:\n",
    "                    explanations.append(\"Good field relevance\")\n",
    "                elif field_similarity >= 0.4:\n",
    "                    explanations.append(\"Moderate field relevance\")\n",
    "                elif field_similarity > 0:\n",
    "                    explanations.append(\"Some field relevance\")\n",
    "                else:\n",
    "                    explanations.append(\"Field not closely related\")\n",
    "                \n",
    "                # 3. Grade Quality (25 points)\n",
    "                if resume_edu.grade:\n",
    "                    gpa = self.convert_grade_to_gpa(resume_edu.grade)\n",
    "                    if gpa:\n",
    "                        if gpa >= 3.5:\n",
    "                            current_score += 25\n",
    "                            explanations.append(f\"Excellent grades (GPA: {gpa:.1f})\")\n",
    "                        elif gpa >= 3.0:\n",
    "                            current_score += 20\n",
    "                            explanations.append(f\"Good grades (GPA: {gpa:.1f})\")\n",
    "                        elif gpa >= 2.5:\n",
    "                            current_score += 15\n",
    "                            explanations.append(f\"Average grades (GPA: {gpa:.1f})\")\n",
    "                        else:\n",
    "                            current_score += 10\n",
    "                            explanations.append(f\"Below average grades (GPA: {gpa:.1f})\")\n",
    "                    else:\n",
    "                        current_score += 12\n",
    "                        explanations.append(\"Grade format not recognized\")\n",
    "                else:\n",
    "                    current_score += 12\n",
    "                    explanations.append(\"No grade information\")\n",
    "                \n",
    "                if current_score > best_match_score:\n",
    "                    best_match_score = current_score\n",
    "                    best_explanation = \"; \".join(explanations)\n",
    "        \n",
    "        return MatchScore(best_match_score, 100.0, best_explanation)\n",
    "\n",
    "class LocationMatcher:\n",
    "    \"\"\"Handles location-based matching between resume and job description\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def normalize_location(self, location_str: str) -> str:\n",
    "        \"\"\"Normalize location string for comparison\"\"\"\n",
    "        if not location_str:\n",
    "            return \"\"\n",
    "        return re.sub(r'[^\\w\\s]', '', location_str.lower().strip())\n",
    "    \n",
    "    def extract_resume_locations(self, resume) -> List[str]:\n",
    "        \"\"\"Extract all location information from resume\"\"\"\n",
    "        locations = []\n",
    "        \n",
    "        # From contact info address\n",
    "        if resume.contact_info.address:\n",
    "            addr = resume.contact_info.address\n",
    "            if addr.city:\n",
    "                locations.append(addr.city)\n",
    "            if addr.state:\n",
    "                locations.append(addr.state)\n",
    "            if addr.country:\n",
    "                locations.append(addr.country)\n",
    "        \n",
    "        # From experience locations\n",
    "        for exp in resume.experience:\n",
    "            if exp.location:\n",
    "                locations.append(exp.location)\n",
    "        \n",
    "        # From education locations\n",
    "        for edu in resume.education:\n",
    "            if edu.location:\n",
    "                locations.append(edu.location)\n",
    "        \n",
    "        return [self.normalize_location(loc) for loc in locations if loc]\n",
    "    \n",
    "    def check_location_match(self, resume_locations: List[str], job_location: str) -> bool:\n",
    "        \"\"\"Check if any resume location matches job location\"\"\"\n",
    "        job_loc_norm = self.normalize_location(job_location)\n",
    "        \n",
    "        for resume_loc in resume_locations:\n",
    "            if resume_loc in job_loc_norm or job_loc_norm in resume_loc:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def match_location(self, resume, job_description) -> MatchScore:\n",
    "        \"\"\"\n",
    "        Match location requirements between resume and job description\n",
    "        \n",
    "        Location Matching Rules:\n",
    "        1. Remote work (100 points):\n",
    "           - Job is remote: Full score regardless of resume location\n",
    "        \n",
    "        2. Hybrid work (90 points):\n",
    "           - Treated as onsite for matching purposes\n",
    "           - Location match required\n",
    "        \n",
    "        3. Onsite work (100 points):\n",
    "           - Must have location match for full score\n",
    "           - No location in resume: 30 points penalty\n",
    "           - No location in JD: No penalty\n",
    "           - No location in both: No penalty\n",
    "        \n",
    "        4. Location match scoring:\n",
    "           - Exact match: Full score\n",
    "           - No match but both have locations: 20 points penalty\n",
    "           - Resume has no location info: 30 points penalty\n",
    "        \"\"\"\n",
    "        \n",
    "        max_score = 100.0\n",
    "        \n",
    "        # Check remote work\n",
    "        if job_description.is_remote:\n",
    "            return MatchScore(max_score, max_score, \"Remote work - location not relevant\")\n",
    "        \n",
    "        # Extract resume locations\n",
    "        resume_locations = self.extract_resume_locations(resume)\n",
    "        \n",
    "        # Get job locations\n",
    "        job_locations = []\n",
    "        if job_description.locations:\n",
    "            for loc in job_description.locations:\n",
    "                if loc.city:\n",
    "                    job_locations.append(loc.city)\n",
    "                if loc.state:\n",
    "                    job_locations.append(loc.state)\n",
    "                if loc.country:\n",
    "                    job_locations.append(loc.country)\n",
    "        \n",
    "        job_locations = [self.normalize_location(loc) for loc in job_locations]\n",
    "        \n",
    "        # No location requirements in job\n",
    "        if not job_locations:\n",
    "            return MatchScore(max_score, max_score, \"No specific location requirements\")\n",
    "        \n",
    "        # No location info in resume - penalty for onsite/hybrid\n",
    "        if not resume_locations:\n",
    "            penalty_score = max_score - 30\n",
    "            return MatchScore(penalty_score, max_score, \n",
    "                            \"No location information in resume - 30 point penalty\")\n",
    "        \n",
    "        # Check for location matches\n",
    "        location_matches = []\n",
    "        for job_loc in job_locations:\n",
    "            for resume_loc in resume_locations:\n",
    "                if self.check_location_match([resume_loc], job_loc):\n",
    "                    location_matches.append((resume_loc, job_loc))\n",
    "        \n",
    "        if location_matches:\n",
    "            match_details = \", \".join([f\"{r} matches {j}\" for r, j in location_matches[:2]])\n",
    "            return MatchScore(max_score, max_score, f\"Location match found: {match_details}\")\n",
    "        else:\n",
    "            penalty_score = max_score - 20\n",
    "            return MatchScore(penalty_score, max_score, \n",
    "                            \"No location match - 20 point penalty\")\n",
    "\n",
    "class ExperienceMatcher:\n",
    "    \"\"\"Handles experience-based matching between resume and job description\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.relevance_threshold = 0.5  # Minimum similarity for relevant experience\n",
    "    \n",
    "    def embed_text(self, text: str):\n",
    "        \"\"\"Generate embeddings for text using the sentence transformer model\"\"\"\n",
    "        return self.model.encode(text, normalize_embeddings=True, show_progress_bar=False)\n",
    "    \n",
    "    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Calculate cosine similarity between two texts using embeddings\"\"\"\n",
    "        try:\n",
    "            vec1 = self.embed_text(text1)\n",
    "            vec2 = self.embed_text(text2)\n",
    "            # Cosine similarity using normalized embeddings\n",
    "            similarity = float(vec1.dot(vec2))\n",
    "            return max(0.0, min(1.0, similarity))  # Clamp between 0 and 1\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def normalize_job_title(self, title: str) -> str:\n",
    "        \"\"\"Normalize job title for better matching\"\"\"\n",
    "        if not title:\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase and remove special characters\n",
    "        normalized = re.sub(r'[^\\w\\s]', ' ', title.lower())\n",
    "        # Remove common words that don't add semantic value\n",
    "        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "        words = [word for word in normalized.split() if word not in stop_words]\n",
    "        return ' '.join(words).strip()\n",
    "    \n",
    "    def parse_date(self, date_str: str) -> Optional[datetime]:\n",
    "        \"\"\"Parse various date formats to datetime object\"\"\"\n",
    "        if not date_str:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Handle \"Present\", \"Current\", etc.\n",
    "            if date_str.lower() in ['present', 'current', 'now', 'ongoing']:\n",
    "                return datetime.now()\n",
    "            \n",
    "            # Try to parse the date\n",
    "            return parser.parse(date_str, fuzzy=True)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def calculate_experience_duration(self, start_date: str, end_date: str) -> float:\n",
    "        \"\"\"Calculate experience duration in years\"\"\"\n",
    "        start = self.parse_date(start_date)\n",
    "        end = self.parse_date(end_date)\n",
    "        \n",
    "        if not start:\n",
    "            return 0.0\n",
    "        \n",
    "        if not end:\n",
    "            end = datetime.now()\n",
    "        \n",
    "        # Calculate difference in years\n",
    "        duration = (end - start).days / 365.25\n",
    "        return max(0.0, duration)\n",
    "    \n",
    "    def calculate_job_title_similarity(self, job_title: str, resume_experiences: List) -> List[Tuple[int, float, float]]:\n",
    "        \"\"\"\n",
    "        Calculate similarity between job title and all resume experiences\n",
    "        Returns: List of (experience_index, similarity_score, years_of_experience)\n",
    "        \"\"\"\n",
    "        job_title_norm = self.normalize_job_title(job_title)\n",
    "        similarities = []\n",
    "        \n",
    "        for i, exp in enumerate(resume_experiences):\n",
    "            exp_title_norm = self.normalize_job_title(exp.job_title)\n",
    "            \n",
    "            # Calculate semantic similarity\n",
    "            similarity = self.calculate_semantic_similarity(job_title_norm, exp_title_norm)\n",
    "            \n",
    "            # Calculate years of experience for this job\n",
    "            years = self.calculate_experience_duration(exp.start_date, exp.end_date)\n",
    "            \n",
    "            similarities.append((i, similarity, years))\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def aggregate_relevant_experience(self, similarities: List[Tuple[int, float, float]]) -> Tuple[float, List[Tuple[int, float]]]:\n",
    "        \"\"\"\n",
    "        Aggregate only relevant experience based on relevance threshold\n",
    "        Returns: (relevant_years, relevant_jobs_details)\n",
    "        \"\"\"\n",
    "        relevant_years = 0.0\n",
    "        relevant_jobs = []\n",
    "        \n",
    "        for exp_idx, similarity, years in similarities:\n",
    "            if similarity >= self.relevance_threshold:\n",
    "                relevant_years += years\n",
    "                relevant_jobs.append((exp_idx, similarity))\n",
    "        \n",
    "        return relevant_years, relevant_jobs\n",
    "    \n",
    "    def calculate_experience_score(self, relevant_years: float, required_min: float, required_max: Optional[float] = None) -> Tuple[float, str]:\n",
    "        \"\"\"\n",
    "        Calculate experience score based only on relevant experience\n",
    "        \"\"\"\n",
    "        \n",
    "        if required_max is None:\n",
    "            required_max = required_min * 1.5\n",
    "\n",
    "        max_score = 100.0\n",
    "\n",
    "        # Calculate score based only on relevant experience\n",
    "        if relevant_years >= required_min:\n",
    "            if relevant_years >= required_max:\n",
    "                final_score = max_score\n",
    "            else:\n",
    "                # Scale between 60-100 based on progress from min to max\n",
    "                progress = (relevant_years - required_min) / (required_max - required_min)\n",
    "                final_score = 60.0 + (progress * 40.0)\n",
    "        else:\n",
    "            # Scale from 0-60 based on progress toward minimum\n",
    "            if required_min > 0:\n",
    "                final_score = (relevant_years / required_min) * 60.0\n",
    "            else:\n",
    "                final_score = 60.0\n",
    "\n",
    "        final_score = min(max_score, final_score)\n",
    "\n",
    "        # Explanation\n",
    "        explanation_parts = []\n",
    "        explanation_parts.append(f\"Relevant experience: {relevant_years:.1f} years\")\n",
    "        explanation_parts.append(f\"Required: {required_min:.1f}-{required_max:.1f} years\")\n",
    "\n",
    "        if relevant_years >= required_min:\n",
    "            explanation_parts.append(\"✓ Meets minimum requirement\")\n",
    "        else:\n",
    "            shortage = required_min - relevant_years\n",
    "            explanation_parts.append(f\"⚠ {shortage:.1f} years short of minimum\")\n",
    "\n",
    "        explanation = \"; \".join(explanation_parts)\n",
    "        \n",
    "        return final_score, explanation\n",
    "\n",
    "    def match_experience(self, resume_experiences: List, job_description) -> MatchScore:\n",
    "        \"\"\"\n",
    "        Match experience requirements between resume and job description\n",
    "        \n",
    "        Experience Matching Rules:\n",
    "        1. Job Title Similarity (Primary factor):\n",
    "           - Uses semantic similarity with threshold of 0.5\n",
    "           - Only experiences above threshold count as \"relevant\"\n",
    "        \n",
    "        2. Years Calculation:\n",
    "           - Only relevant years are considered\n",
    "           - Non-relevant experience is completely ignored\n",
    "        \n",
    "        3. Scoring (100 points total):\n",
    "           - Based entirely on relevant experience\n",
    "           - 0-60 points: Progress toward minimum requirement\n",
    "           - 60-100 points: Progress from minimum to maximum requirement\n",
    "        \n",
    "        4. Requirements Matching:\n",
    "           - Compares against min/max experience requirements\n",
    "           - Penalties for not meeting minimum requirements\n",
    "           - Bonuses for exceeding requirements\n",
    "        \"\"\"\n",
    "        \n",
    "        if not resume_experiences:\n",
    "            return MatchScore(0.0, 100.0, \"No work experience found in resume\")\n",
    "        \n",
    "        # Get experience requirements from job description\n",
    "        required_min = 0.0\n",
    "        required_max = None\n",
    "        \n",
    "        if (job_description.qualifications and \n",
    "            job_description.qualifications.experience_years):\n",
    "            exp_req = job_description.qualifications.experience_years\n",
    "            required_min = exp_req.min or 0.0\n",
    "            required_max = exp_req.max\n",
    "        \n",
    "        # If no specific requirements, use job level as indicator\n",
    "        if required_min == 0.0 and job_description.job_level:\n",
    "            level_requirements = {\n",
    "                'entry': (0, 2),\n",
    "                'mid': (2, 3), \n",
    "                'senior': (5, 8),\n",
    "                'lead': (7, 10),\n",
    "                'manager': (5, 12),\n",
    "                'director': (8, 15),\n",
    "                'executive': (10, 20)\n",
    "            }\n",
    "            if job_description.job_level.value in level_requirements:\n",
    "                required_min, required_max = level_requirements[job_description.job_level.value]\n",
    "        \n",
    "        # Default minimum if nothing specified\n",
    "        if required_min == 0.0:\n",
    "            required_min = 1.0  # Default to 1 year minimum\n",
    "        \n",
    "        # Calculate similarities with job title\n",
    "        job_title = job_description.title\n",
    "        similarities = self.calculate_job_title_similarity(job_title, resume_experiences)\n",
    "        \n",
    "        # Aggregate only relevant experience\n",
    "        relevant_years, relevant_jobs = self.aggregate_relevant_experience(similarities)\n",
    "        \n",
    "        # Calculate final score based only on relevant experience\n",
    "        score, explanation = self.calculate_experience_score(\n",
    "            relevant_years, required_min, required_max\n",
    "        )\n",
    "        \n",
    "        # Add details about relevant jobs to explanation\n",
    "        if relevant_jobs:\n",
    "            job_details = []\n",
    "            for exp_idx, similarity in relevant_jobs[:3]:  # Show top 3 relevant jobs\n",
    "                exp = resume_experiences[exp_idx]\n",
    "                job_details.append(f\"{exp.job_title} ({similarity:.2f} similarity)\")\n",
    "            \n",
    "            if job_details:\n",
    "                explanation += f\"; Relevant roles: {', '.join(job_details)}\"\n",
    "        elif relevant_years == 0:\n",
    "            explanation += \"; No relevant experience found\"\n",
    "        \n",
    "        return MatchScore(score, 100.0, explanation)\n",
    "\n",
    "class ConstraintMatcher:\n",
    "    \"\"\"Main class that combines all matching algorithms\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.education_matcher = EducationMatcher(self.model)\n",
    "        self.location_matcher = LocationMatcher()\n",
    "        self.experience_matcher = ExperienceMatcher(self.model)\n",
    "    \n",
    "    def calculate_overall_score(self, resume, job_description, weights: Dict[str, float] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate overall matching score between resume and job description\n",
    "        \n",
    "        Updated weights:\n",
    "        - Education: 0.25 (25%)\n",
    "        - Location: 0.25 (25%)\n",
    "        - Experience: 0.35 (35%) - Now implemented\n",
    "        \"\"\"\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'education': 0.35,\n",
    "                'location': 0.30,\n",
    "                'experience': 0.35,  \n",
    "                'skills' : 0.0\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Education matching\n",
    "        if job_description.qualifications and job_description.qualifications.education:\n",
    "            education_score = self.education_matcher.match_education(\n",
    "                resume.education, \n",
    "                job_description.qualifications.education\n",
    "            )\n",
    "        else:\n",
    "            education_score = MatchScore(80.0, 100.0, \"No specific education requirements\")\n",
    "        \n",
    "        results['education'] = {\n",
    "            'score': education_score.score,\n",
    "            'max_score': education_score.max_score,\n",
    "            'normalized_score': education_score.normalized_score,\n",
    "            'explanation': education_score.explanation,\n",
    "            'weight': weights['education']\n",
    "        }\n",
    "        \n",
    "        # Location matching\n",
    "        location_score = self.location_matcher.match_location(resume, job_description)\n",
    "        results['location'] = {\n",
    "            'score': location_score.score,\n",
    "            'max_score': location_score.max_score,\n",
    "            'normalized_score': location_score.normalized_score,\n",
    "            'explanation': location_score.explanation,\n",
    "            'weight': weights['location']\n",
    "        }\n",
    "        \n",
    "        # Experience matching - Now implemented!\n",
    "        experience_score = self.experience_matcher.match_experience(resume.experience, job_description)\n",
    "        results['experience'] = {\n",
    "            'score': experience_score.score,\n",
    "            'max_score': experience_score.max_score,\n",
    "            'normalized_score': experience_score.normalized_score,\n",
    "            'explanation': experience_score.explanation,\n",
    "            'weight': weights['experience']\n",
    "        }\n",
    "        \n",
    "        # Placeholder for skills (reduced weight)\n",
    "        results['skills'] = {\n",
    "            'score': 60.0, 'max_score': 100.0, 'normalized_score': 0.6,\n",
    "            'explanation': 'Skills matching not implemented yet',\n",
    "            'weight': weights['skills']\n",
    "        }\n",
    "        \n",
    "        # Calculate weighted overall score\n",
    "        total_weighted_score = sum(\n",
    "            results[component]['normalized_score'] * results[component]['weight']\n",
    "            for component in results\n",
    "        )\n",
    "        \n",
    "        results['overall'] = {\n",
    "            'score': total_weighted_score * 100,\n",
    "            'max_score': 100.0,\n",
    "            'normalized_score': total_weighted_score,\n",
    "            'breakdown': {k: v for k, v in results.items() if k != 'overall'}\n",
    "        }\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = manager.get_all_resumes()\n",
    "jobs = manager.get_all_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint Based Macthes for Machine Learning Engineer\n",
      "Name: Ali Suleman - Score 63.6741716859889\n",
      "\n",
      "Name: Zohaib Khan - Score 61.67070948958398\n",
      "\n",
      "Name: Hilal Aziz - Score 57.62930515621477\n",
      "\n",
      "------------\n",
      "Constraint Based Macthes for Machine Learning Engineer\n",
      "Name: Ali Suleman - Score 67.80429432653425\n",
      "\n",
      "Name: Zohaib Khan - Score 61.56930613676707\n",
      "\n",
      "Name: Hilal Aziz - Score 60.26456126698601\n",
      "\n",
      "------------\n",
      "Constraint Based Macthes for Machine Learning Engineer (NLP)\n",
      "Name: Ali Suleman - Score 64.7131391335924\n",
      "\n",
      "Name: Zohaib Khan - Score 61.38311371326446\n",
      "\n",
      "Name: Hilal Aziz - Score 56.65595227527618\n",
      "\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matcher = ConstraintMatcher(model=model)\n",
    "scores = []\n",
    "for job in jobs:\n",
    "    parsed_job = job['parsed_data']\n",
    "    jd = JobDescription(**parsed_job)\n",
    "    print(f\"Constraint Based Macthes for {jd.title}\")\n",
    "    for resume in resumes:\n",
    "        parsed_resume = resume['parsed_data']\n",
    "        res = Resume(**parsed_resume)\n",
    "        results = matcher.calculate_overall_score(res, jd)\n",
    "        print(f\"Name: {res.basic_info.full_name} - Score {results['overall']['score']}\\n\")\n",
    "        scores.append((jd.title,res.basic_info.full_name,results))\n",
    "    print(\"------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class EmbeddingType(str, Enum):\n",
    "    SKILLS = \"skills\"\n",
    "    EDUCATION = \"education\"\n",
    "    EXPERIENCE_TITLE = \"experience_title\"\n",
    "    EXPERIENCE_RESPONSIBILITIES = \"experience_responsibilities\"\n",
    "    EXPERIENCE_SKILLS = \"experience_skills\"\n",
    "    PROJECTS = \"projects\"\n",
    "    SUMMARY = \"summary\"\n",
    "\n",
    "@dataclass\n",
    "class SectionWeights:\n",
    "    skills: float = 0.25\n",
    "    education: float = 0.15\n",
    "    experience_title: float = 0.20\n",
    "    experience_responsibilities: float = 0.20\n",
    "    experience_skills: float = 0.10\n",
    "    projects: float = 0.05\n",
    "    summary: float = 0.05\n",
    "\n",
    "class SemanticMatcher:\n",
    "    def __init__(self, faiss_index_path: str = \"./faiss_indexes\", model_name: str = \"hkunlp/instructor-large\"):\n",
    "        self.faiss_index_path = faiss_index_path\n",
    "        try:\n",
    "            self.model = INSTRUCTOR(model_name)\n",
    "        except TypeError as e:\n",
    "            if \"token\" in str(e):\n",
    "                try:\n",
    "                    self.model = INSTRUCTOR(model_name, cache_folder=None)\n",
    "                except:\n",
    "                    print(f\"Failed to load {model_name}, falling back to instructor-large\")\n",
    "                    self.model = INSTRUCTOR(\"hkunlp/instructor-large\")\n",
    "            else:\n",
    "                raise e\n",
    "        self.section_weights = SectionWeights()\n",
    "        os.makedirs(faiss_index_path, exist_ok=True)\n",
    "        self.indexes = {}\n",
    "        self.id_mappings = {}\n",
    "        self.processed_documents = set()  # Track processed documents to avoid regeneration\n",
    "        self._load_or_create_indexes()\n",
    "    \n",
    "    def _load_or_create_indexes(self):\n",
    "        for embedding_type in EmbeddingType:\n",
    "            index_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}.index\")\n",
    "            mapping_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}_mapping.pkl\")\n",
    "            processed_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}_processed.pkl\")\n",
    "            \n",
    "            if os.path.exists(index_file) and os.path.exists(mapping_file):\n",
    "                self.indexes[embedding_type.value] = faiss.read_index(index_file)\n",
    "                with open(mapping_file, 'rb') as f:\n",
    "                    self.id_mappings[embedding_type.value] = pickle.load(f)\n",
    "                \n",
    "                # Load processed documents list if exists\n",
    "                if os.path.exists(processed_file):\n",
    "                    with open(processed_file, 'rb') as f:\n",
    "                        processed_docs = pickle.load(f)\n",
    "                        self.processed_documents.update(processed_docs)\n",
    "                \n",
    "                logger.info(f\"Loaded existing index for {embedding_type.value}\")\n",
    "            else:\n",
    "                self.indexes[embedding_type.value] = None\n",
    "                self.id_mappings[embedding_type.value] = {}\n",
    "                logger.info(f\"Will create new index for {embedding_type.value}\")\n",
    "    \n",
    "    def _is_document_processed(self, doc_id: str, doc_type: str) -> bool:\n",
    "        \"\"\"Check if a document has already been processed\"\"\"\n",
    "        return f\"{doc_type}_{doc_id}\" in self.processed_documents\n",
    "    \n",
    "    def _mark_document_processed(self, doc_id: str, doc_type: str):\n",
    "        \"\"\"Mark a document as processed\"\"\"\n",
    "        self.processed_documents.add(f\"{doc_type}_{doc_id}\")\n",
    "    \n",
    "    def _get_embedding(self, text: str, instruction: str) -> np.ndarray:\n",
    "        if not text or text.strip() == \"\":\n",
    "            return np.zeros(768)\n",
    "        \n",
    "        try:\n",
    "            embedding = self.model.encode([[instruction, text]])\n",
    "            return embedding[0]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return np.zeros(768)\n",
    "    \n",
    "    def _extract_resume_sections(self, resume) -> Dict[str, str]:\n",
    "        \"\"\"Extract relevant sections from resume for embedding\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Skills\n",
    "        skills_text = \", \".join([skill.skill_name for skill in resume.skills])\n",
    "        sections[EmbeddingType.SKILLS.value] = skills_text\n",
    "        \n",
    "        # Education\n",
    "        education_texts = []\n",
    "        for edu in resume.education:\n",
    "            edu_text = f\"{edu.degree} in {edu.field or 'N/A'} from {edu.institution or 'N/A'}\"\n",
    "            if edu.courses:\n",
    "                edu_text += f\" with courses: {', '.join(edu.courses)}\"\n",
    "            education_texts.append(edu_text)\n",
    "        sections[EmbeddingType.EDUCATION.value] = \". \".join(education_texts)\n",
    "        \n",
    "        # Experience titles\n",
    "        experience_titles = [exp.job_title for exp in resume.experience]\n",
    "        sections[EmbeddingType.EXPERIENCE_TITLE.value] = \", \".join(experience_titles)\n",
    "        \n",
    "        # Experience responsibilities\n",
    "        all_responsibilities = []\n",
    "        for exp in resume.experience:\n",
    "            all_responsibilities.extend(exp.responsibilities)\n",
    "        sections[EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value] = \". \".join(all_responsibilities)\n",
    "        \n",
    "        # Experience skills\n",
    "        all_exp_skills = []\n",
    "        for exp in resume.experience:\n",
    "            all_exp_skills.extend(exp.skills_used)\n",
    "        sections[EmbeddingType.EXPERIENCE_SKILLS.value] = \", \".join(all_exp_skills)\n",
    "        \n",
    "        # Projects\n",
    "        project_texts = []\n",
    "        for project in resume.projects:\n",
    "            proj_text = f\"{project.title}: {project.description or 'N/A'}\"\n",
    "            if project.technologies:\n",
    "                proj_text += f\" using {', '.join(project.technologies)}\"\n",
    "            project_texts.append(proj_text)\n",
    "        sections[EmbeddingType.PROJECTS.value] = \". \".join(project_texts)\n",
    "        \n",
    "        # Summary\n",
    "        sections[EmbeddingType.SUMMARY.value] = resume.summary or \"\"\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _extract_job_sections(self, job) -> Dict[str, str]:\n",
    "        \"\"\"Extract relevant sections from job description for embedding\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Skills (mandatory + optional + nice_to_have)\n",
    "        skills_texts = []\n",
    "        if job.skills:\n",
    "            if job.skills.mandatory:\n",
    "                skills_texts.extend(job.skills.mandatory)\n",
    "            if job.skills.optional:\n",
    "                skills_texts.extend(job.skills.optional)\n",
    "            if job.skills.tools:\n",
    "                skills_texts.extend(job.skills.tools)\n",
    "        if job.nice_to_have:\n",
    "            skills_texts.extend(job.nice_to_have)\n",
    "        sections[EmbeddingType.SKILLS.value] = \", \".join(skills_texts)\n",
    "        \n",
    "        # Education\n",
    "        education_texts = []\n",
    "        if job.qualifications and job.qualifications.education:\n",
    "            for edu_req in job.qualifications.education:\n",
    "                edu_text = f\"{edu_req.degree or 'N/A'} in {edu_req.field_of_study or 'N/A'}\"\n",
    "                education_texts.append(edu_text)\n",
    "        sections[EmbeddingType.EDUCATION.value] = \". \".join(education_texts)\n",
    "        \n",
    "        # Job title\n",
    "        sections[EmbeddingType.EXPERIENCE_TITLE.value] = job.title\n",
    "        \n",
    "        # Responsibilities and description\n",
    "        resp_texts = []\n",
    "        if job.responsibilities:\n",
    "            resp_texts.extend(job.responsibilities)\n",
    "        if job.description:\n",
    "            resp_texts.append(job.description)\n",
    "        sections[EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value] = \". \".join(resp_texts)\n",
    "        \n",
    "        # Skills (for experience skills matching)\n",
    "        sections[EmbeddingType.EXPERIENCE_SKILLS.value] = sections[EmbeddingType.SKILLS.value]\n",
    "        \n",
    "        # Requirements and nice_to_have (for projects matching)\n",
    "        proj_texts = []\n",
    "        if job.requirements:\n",
    "            proj_texts.extend(job.requirements)\n",
    "        if job.nice_to_have:\n",
    "            proj_texts.extend(job.nice_to_have)\n",
    "        sections[EmbeddingType.PROJECTS.value] = \". \".join(proj_texts)\n",
    "        \n",
    "        # Summary\n",
    "        sections[EmbeddingType.SUMMARY.value] = job.summary or job.description or \"\"\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _add_to_faiss_index(self, embedding_type: str, embedding: np.ndarray, doc_id: str, doc_type: str):\n",
    "        \"\"\"Add embedding to FAISS index\"\"\"\n",
    "        if self.indexes[embedding_type] is None:\n",
    "            dimension = embedding.shape[0]\n",
    "            self.indexes[embedding_type] = faiss.IndexFlatIP(dimension)\n",
    "            \n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "        embedding = embedding.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        current_size = self.indexes[embedding_type].ntotal\n",
    "        self.indexes[embedding_type].add(embedding)\n",
    "        \n",
    "        self.id_mappings[embedding_type][current_size] = {\n",
    "            'id': doc_id,\n",
    "            'type': doc_type\n",
    "        }\n",
    "    \n",
    "    def _save_indexes(self):\n",
    "        \"\"\"Save FAISS indexes, mappings, and processed documents to disk\"\"\"\n",
    "        for embedding_type in EmbeddingType:\n",
    "            if self.indexes[embedding_type.value] is not None:\n",
    "                index_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}.index\")\n",
    "                mapping_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}_mapping.pkl\")\n",
    "                processed_file = os.path.join(self.faiss_index_path, f\"{embedding_type.value}_processed.pkl\")\n",
    "                \n",
    "                faiss.write_index(self.indexes[embedding_type.value], index_file)\n",
    "                with open(mapping_file, 'wb') as f:\n",
    "                    pickle.dump(self.id_mappings[embedding_type.value], f)\n",
    "                with open(processed_file, 'wb') as f:\n",
    "                    pickle.dump(list(self.processed_documents), f)\n",
    "    \n",
    "    def create_resume_embeddings(self, resume, resume_id: str):\n",
    "        \"\"\"Create and store embeddings for a resume - only if not already processed\"\"\"\n",
    "        if self._is_document_processed(resume_id, 'resume'):\n",
    "            logger.info(f\"Resume {resume_id} already processed, skipping embedding generation\")\n",
    "            return\n",
    "        \n",
    "        logger.info(f\"Creating embeddings for resume {resume_id}\")\n",
    "        \n",
    "        sections = self._extract_resume_sections(resume)\n",
    "        \n",
    "        instructions = {\n",
    "            EmbeddingType.SKILLS.value: \"Represent the professional skills and competencies\",\n",
    "            EmbeddingType.EDUCATION.value: \"Represent the educational background and qualifications\",\n",
    "            EmbeddingType.EXPERIENCE_TITLE.value: \"Represent the job titles and career progression\",\n",
    "            EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value: \"Represent the work responsibilities and achievements\",\n",
    "            EmbeddingType.EXPERIENCE_SKILLS.value: \"Represent the technical skills used in work experience\",\n",
    "            EmbeddingType.PROJECTS.value: \"Represent the project experience and technical implementations\",\n",
    "            EmbeddingType.SUMMARY.value: \"Represent the professional summary and career overview\"\n",
    "        }\n",
    "        \n",
    "        for section_type, text in sections.items():\n",
    "            if text and text.strip():\n",
    "                instruction = instructions[section_type]\n",
    "                embedding = self._get_embedding(text, instruction)\n",
    "                self._add_to_faiss_index(section_type, embedding, resume_id, 'resume')\n",
    "        \n",
    "        self._mark_document_processed(resume_id, 'resume')\n",
    "        self._save_indexes()\n",
    "        logger.info(f\"Successfully created embeddings for resume {resume_id}\")\n",
    "    \n",
    "    def create_job_embeddings(self, job, job_id: str):\n",
    "        \"\"\"Create and store embeddings for a job description - only if not already processed\"\"\"\n",
    "        if self._is_document_processed(job_id, 'job'):\n",
    "            logger.info(f\"Job {job_id} already processed, skipping embedding generation\")\n",
    "            return\n",
    "        \n",
    "        logger.info(f\"Creating embeddings for job {job_id}\")\n",
    "        \n",
    "        sections = self._extract_job_sections(job)\n",
    "        \n",
    "        instructions = {\n",
    "            EmbeddingType.SKILLS.value: \"Represent the required skills and competencies for the job\",\n",
    "            EmbeddingType.EDUCATION.value: \"Represent the educational requirements for the job\",\n",
    "            EmbeddingType.EXPERIENCE_TITLE.value: \"Represent the job title and role requirements\",\n",
    "            EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value: \"Represent the job responsibilities and expectations\",\n",
    "            EmbeddingType.EXPERIENCE_SKILLS.value: \"Represent the technical skills required for the job\",\n",
    "            EmbeddingType.PROJECTS.value: \"Represent the project requirements and technical expectations\",\n",
    "            EmbeddingType.SUMMARY.value: \"Represent the job summary and role overview\"\n",
    "        }\n",
    "        \n",
    "        for section_type, text in sections.items():\n",
    "            if text and text.strip():\n",
    "                instruction = instructions[section_type]\n",
    "                embedding = self._get_embedding(text, instruction)\n",
    "                self._add_to_faiss_index(section_type, embedding, job_id, 'job')\n",
    "        \n",
    "        self._mark_document_processed(job_id, 'job')\n",
    "        self._save_indexes()\n",
    "        logger.info(f\"Successfully created embeddings for job {job_id}\")\n",
    "    \n",
    "    def match_resume_and_job(self, resume, resume_id: str, job, job_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Match a resume against a job description and return detailed scoring\"\"\"\n",
    "        logger.info(f\"Matching resume {resume_id} with job {job_id}\")\n",
    "        \n",
    "        resume_sections = self._extract_resume_sections(resume)\n",
    "        job_sections = self._extract_job_sections(job)\n",
    "        \n",
    "        section_scores = {}\n",
    "        \n",
    "        instructions = {\n",
    "            EmbeddingType.SKILLS.value: \"Represent the professional skills and competencies\",\n",
    "            EmbeddingType.EDUCATION.value: \"Represent the educational background and qualifications\",\n",
    "            EmbeddingType.EXPERIENCE_TITLE.value: \"Represent the job titles and career progression\",\n",
    "            EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value: \"Represent the work responsibilities and achievements\",\n",
    "            EmbeddingType.EXPERIENCE_SKILLS.value: \"Represent the technical skills used in work experience\",\n",
    "            EmbeddingType.PROJECTS.value: \"Represent the project experience and technical implementations\",\n",
    "            EmbeddingType.SUMMARY.value: \"Represent the professional summary and career overview\"\n",
    "        }\n",
    "        \n",
    "        for section_type in EmbeddingType:\n",
    "            section_name = section_type.value\n",
    "            resume_text = resume_sections.get(section_name, \"\")\n",
    "            job_text = job_sections.get(section_name, \"\")\n",
    "            \n",
    "            if resume_text and job_text:\n",
    "                instruction = instructions[section_name]\n",
    "                resume_embedding = self._get_embedding(resume_text, instruction)\n",
    "                job_embedding = self._get_embedding(job_text, instruction)\n",
    "                \n",
    "                similarity = cosine_similarity(\n",
    "                    resume_embedding.reshape(1, -1),\n",
    "                    job_embedding.reshape(1, -1)\n",
    "                )[0][0]\n",
    "                \n",
    "                section_scores[section_name] = max(0.0, similarity)\n",
    "            else:\n",
    "                section_scores[section_name] = 0.0\n",
    "        \n",
    "        overall_score = (\n",
    "            section_scores.get(EmbeddingType.SKILLS.value, 0) * self.section_weights.skills +\n",
    "            section_scores.get(EmbeddingType.EDUCATION.value, 0) * self.section_weights.education +\n",
    "            section_scores.get(EmbeddingType.EXPERIENCE_TITLE.value, 0) * self.section_weights.experience_title +\n",
    "            section_scores.get(EmbeddingType.EXPERIENCE_RESPONSIBILITIES.value, 0) * self.section_weights.experience_responsibilities +\n",
    "            section_scores.get(EmbeddingType.EXPERIENCE_SKILLS.value, 0) * self.section_weights.experience_skills +\n",
    "            section_scores.get(EmbeddingType.PROJECTS.value, 0) * self.section_weights.projects +\n",
    "            section_scores.get(EmbeddingType.SUMMARY.value, 0) * self.section_weights.summary\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'overall_score': overall_score,\n",
    "            'section_scores': section_scores,\n",
    "            'resume_id': resume_id,\n",
    "            'job_id': job_id,\n",
    "            'weights_used': {\n",
    "                'skills': self.section_weights.skills,\n",
    "                'education': self.section_weights.education,\n",
    "                'experience_title': self.section_weights.experience_title,\n",
    "                'experience_responsibilities': self.section_weights.experience_responsibilities,\n",
    "                'experience_skills': self.section_weights.experience_skills,\n",
    "                'projects': self.section_weights.projects,\n",
    "                'summary': self.section_weights.summary\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Match completed. Overall score: {overall_score:.3f}\")\n",
    "        return result\n",
    "\n",
    "class HybridMatcher:\n",
    "    def __init__(self, constraint_matcher: ConstraintMatcher, mongodb_manager: MongoDBManager, faiss_index_path: str = \"./faiss_indexes\"):\n",
    "        self.mongodb_manager = mongodb_manager\n",
    "        self.semantic_matcher = SemanticMatcher(faiss_index_path)\n",
    "        self.cm = constraint_matcher\n",
    "    \n",
    "    def process_resume(self, resume_id: str):\n",
    "        \"\"\"Process a single resume - create embeddings\"\"\"\n",
    "        try:\n",
    "            resume_data = self.mongodb_manager.get_resume_by_id(resume_id)['parsed_data']\n",
    "            if not resume_data:\n",
    "                raise ValueError(f\"Resume {resume_id} not found\")\n",
    "            \n",
    "            # Assuming Resume is a Pydantic model or dataclass\n",
    "            pydantic_resume = Resume(**resume_data)      \n",
    "            self.semantic_matcher.create_resume_embeddings(pydantic_resume, resume_id)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing resume {resume_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process_job(self, job_id: str):\n",
    "        \"\"\"Process a single job - create embeddings\"\"\"\n",
    "        try:\n",
    "            job_data = self.mongodb_manager.get_job_by_id(job_id)\n",
    "            if not job_data:\n",
    "                raise ValueError(f\"Job {job_id} not found\")\n",
    "            job_data = job_data['parsed_data']\n",
    "            pydantic_job = JobDescription(**job_data)\n",
    "            self.semantic_matcher.create_job_embeddings(pydantic_job, job_id)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing job {job_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def match_resume_to_job(self, resume_id: str, job_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Match a resume to a job and return similarity score\"\"\"\n",
    "        try:\n",
    "            resume_data = self.mongodb_manager.get_resume_by_id(resume_id)\n",
    "            job_data = self.mongodb_manager.get_job_by_id(job_id)\n",
    "            \n",
    "            if not resume_data:\n",
    "                raise ValueError(f\"Resume {resume_id} not found\")\n",
    "            if not job_data:\n",
    "                raise ValueError(f\"Job {job_id} not found\")\n",
    "            \n",
    "            resume_data = resume_data['parsed_data']\n",
    "            job_data = job_data['parsed_data']\n",
    "\n",
    "            pydantic_resume = Resume(**resume_data)\n",
    "            pydantic_job = JobDescription(**job_data)\n",
    "            \n",
    "            return self.semantic_matcher.match_resume_and_job(\n",
    "                pydantic_resume, resume_id, pydantic_job, job_id\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error matching resume {resume_id} to job {job_id}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def match_all_applicants_for_job(self, job_id: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Match all applicants for a specific job and return aggregated results.\n",
    "        \n",
    "        Args:\n",
    "            job_id: The job ID to match applicants against\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing applicant information and match scores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting matching process for job {job_id}\")\n",
    "            \n",
    "            # Get job data\n",
    "            job_data = self.mongodb_manager.get_job_by_id(job_id)\n",
    "            if not job_data:\n",
    "                raise ValueError(f\"Job {job_id} not found\")\n",
    "            \n",
    "            # Create job embeddings (only if not already processed)\n",
    "            job_parsed_data = job_data['parsed_data']\n",
    "            pydantic_job = JobDescription(**job_parsed_data)\n",
    "            self.semantic_matcher.create_job_embeddings(pydantic_job, job_id)\n",
    "            \n",
    "            # Get all applicants for this job\n",
    "            applications = self.mongodb_manager.get_job_applicants(job_id)\n",
    "            logger.info(f\"Found {len(applications)} applicants for job {job_id}\")\n",
    "            \n",
    "            if not applications:\n",
    "                logger.info(f\"No applicants found for job {job_id}\")\n",
    "                return []\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for application in applications:\n",
    "                try:\n",
    "                    resume_id = str(application['resume_id'])\n",
    "                    user_id = str(application['user_id'])\n",
    "                    \n",
    "                    # Get resume data\n",
    "                    resume_data = self.mongodb_manager.get_resume_by_id(resume_id)\n",
    "                    if not resume_data:\n",
    "                        logger.warning(f\"Resume {resume_id} not found for application\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Constraint Results\n",
    "                    \n",
    "\n",
    "                    # Create resume embeddings (only if not already processed)\n",
    "                    resume_parsed_data = resume_data['parsed_data']\n",
    "                    pydantic_resume = Resume(**resume_parsed_data)\n",
    "                    \n",
    "                    self.semantic_matcher.create_resume_embeddings(pydantic_resume, resume_id)\n",
    "                    \n",
    "                    applicant_name = pydantic_resume.basic_info.full_name\n",
    "\n",
    "                    match_result = self.semantic_matcher.match_resume_and_job(\n",
    "                        pydantic_resume, resume_id, pydantic_job, job_id\n",
    "                    )\n",
    "                    c_results = self.cm.calculate_overall_score(resume=pydantic_resume,job_description=pydantic_job)\n",
    "                    \n",
    "                    \n",
    "                    # Aggregate results\n",
    "                    applicant_result = {\n",
    "                        'applicant_name': applicant_name,\n",
    "                        'user_id': user_id,\n",
    "                        'resume_id': resume_id,\n",
    "                        'application_id': str(application['_id']),\n",
    "                        'applied_at': application.get('applied_at'),\n",
    "                        'status': application.get('status', 'submitted'),\n",
    "                        'overall_score': 0.6 * match_result['overall_score'] + 0.4 * (c_results['overall']['score']/100),\n",
    "                        'section_scores': {\n",
    "                            'skills': match_result['section_scores'].get('skills', 0.0),\n",
    "                            'education': match_result['section_scores'].get('education', 0.0),\n",
    "                            'experience_title': match_result['section_scores'].get('experience_title', 0.0),\n",
    "                            'experience_responsibilities': match_result['section_scores'].get('experience_responsibilities', 0.0),\n",
    "                            'experience_skills': match_result['section_scores'].get('experience_skills', 0.0),\n",
    "                            'projects': match_result['section_scores'].get('projects', 0.0),\n",
    "                            'summary': match_result['section_scores'].get('summary', 0.0)\n",
    "                        },\n",
    "                        'constraint_results' : c_results,\n",
    "                        'cover_message': application.get('cover_message', ''),\n",
    "                        'weights_used': match_result['weights_used']\n",
    "                    }\n",
    "                    \n",
    "                    results.append(applicant_result)\n",
    "                    logger.info(f\"Processed applicant {applicant_name} with score {applicant_result['overall_score']:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing application {application.get('_id')}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Sort results by overall score (highest first)\n",
    "            results.sort(key=lambda x: x['overall_score'], reverse=True)\n",
    "            \n",
    "            logger.info(f\"Completed matching for job {job_id}. Processed {len(results)} applicants\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in match_all_applicants_for_job for job {job_id}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_top_candidates(self, job_id: str, top_n: int = 10) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get top N candidates for a job based on matching scores.\n",
    "        \n",
    "        Args:\n",
    "            job_id: The job ID to get candidates for\n",
    "            top_n: Number of top candidates to return\n",
    "            \n",
    "        Returns:\n",
    "            List of top candidates with their scores\n",
    "        \"\"\"\n",
    "        results = self.match_all_applicants_for_job(job_id)\n",
    "        return results[:top_n]\n",
    "    \n",
    "    def get_candidates_above_threshold(self, job_id: str, threshold: float = 0.7) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get candidates with overall score above a certain threshold.\n",
    "        \n",
    "        Args:\n",
    "            job_id: The job ID to get candidates for\n",
    "            threshold: Minimum overall score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of candidates above threshold\n",
    "        \"\"\"\n",
    "        results = self.match_all_applicants_for_job(job_id)\n",
    "        return [result for result in results if result['overall_score'] >= threshold]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "INFO:__main__:Loaded existing index for skills\n",
      "INFO:__main__:Loaded existing index for education\n",
      "INFO:__main__:Loaded existing index for experience_title\n",
      "INFO:__main__:Loaded existing index for experience_responsibilities\n",
      "INFO:__main__:Loaded existing index for experience_skills\n",
      "INFO:__main__:Loaded existing index for projects\n",
      "INFO:__main__:Loaded existing index for summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "cm = ConstraintMatcher(model=model)\n",
    "matcher = HybridMatcher(constraint_matcher=cm,mongodb_manager=manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating embeddings for resume 683ee9c8be4f92cf16c108e3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully created embeddings for resume 683ee9c8be4f92cf16c108e3\n",
      "INFO:__main__:Creating embeddings for resume 683eeafcbe4f92cf16c108e6\n",
      "INFO:__main__:Successfully created embeddings for resume 683eeafcbe4f92cf16c108e6\n",
      "INFO:__main__:Creating embeddings for resume 683eeba5be4f92cf16c108e8\n",
      "INFO:__main__:Successfully created embeddings for resume 683eeba5be4f92cf16c108e8\n"
     ]
    }
   ],
   "source": [
    "for resume in manager.get_all_resumes():\n",
    "    matcher.process_resume(resume['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating embeddings for job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Successfully created embeddings for job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Creating embeddings for job 6842e8f765e970b23f9fc081\n",
      "INFO:__main__:Successfully created embeddings for job 6842e8f765e970b23f9fc081\n",
      "INFO:__main__:Creating embeddings for job 6842ea7765e970b23f9fc082\n",
      "INFO:__main__:Successfully created embeddings for job 6842ea7765e970b23f9fc082\n"
     ]
    }
   ],
   "source": [
    "for job in manager.get_all_jobs():\n",
    "    matcher.process_job(job['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting matching process for job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Job 682615488cdb8c6bdb1aa95a already processed, skipping embedding generation\n",
      "INFO:__main__:Found 4 applicants for job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Resume 683ee9c8be4f92cf16c108e3 already processed, skipping embedding generation\n",
      "INFO:__main__:Matching resume 683ee9c8be4f92cf16c108e3 with job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Match completed. Overall score: 0.858\n",
      "INFO:__main__:Processed applicant Ali Suleman with score 0.769\n",
      "INFO:__main__:Resume 683eeafcbe4f92cf16c108e6 already processed, skipping embedding generation\n",
      "INFO:__main__:Matching resume 683eeafcbe4f92cf16c108e6 with job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Match completed. Overall score: 0.702\n",
      "INFO:__main__:Processed applicant Zohaib Khan with score 0.668\n",
      "INFO:__main__:Resume 683eeba5be4f92cf16c108e8 already processed, skipping embedding generation\n",
      "INFO:__main__:Matching resume 683eeba5be4f92cf16c108e8 with job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Match completed. Overall score: 0.754\n",
      "INFO:__main__:Processed applicant Hilal Aziz with score 0.683\n",
      "INFO:__main__:Creating embeddings for resume 6845b3120a50408692826d02\n",
      "INFO:__main__:Successfully created embeddings for resume 6845b3120a50408692826d02\n",
      "INFO:__main__:Matching resume 6845b3120a50408692826d02 with job 682615488cdb8c6bdb1aa95a\n",
      "INFO:__main__:Match completed. Overall score: 0.727\n",
      "INFO:__main__:Processed applicant Muneeb Ur Rehman with score 0.667\n",
      "INFO:__main__:Completed matching for job 682615488cdb8c6bdb1aa95a. Processed 4 applicants\n"
     ]
    }
   ],
   "source": [
    "job_id = \"682615488cdb8c6bdb1aa95a\"\n",
    "all_matches = matcher.match_all_applicants_for_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'applicant_name': 'Ali Suleman',\n",
       "  'user_id': '683ee7bb72bd949dd6fb1036',\n",
       "  'resume_id': '683ee9c8be4f92cf16c108e3',\n",
       "  'application_id': '683eeaa4be4f92cf16c108e5',\n",
       "  'applied_at': datetime.datetime(2025, 6, 3, 12, 29, 24, 471000),\n",
       "  'status': 'submitted',\n",
       "  'overall_score': 0.7693903880111981,\n",
       "  'section_scores': {'skills': 0.91349924,\n",
       "   'education': 0.8764814,\n",
       "   'experience_title': 0.9110134,\n",
       "   'experience_responsibilities': 0.9010321,\n",
       "   'experience_skills': 0.9171331,\n",
       "   'projects': 0.87706804,\n",
       "   'summary': 0.0},\n",
       "  'constraint_results': {'education': {'score': 83.809455037117,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.8380945503711701,\n",
       "    'explanation': 'Exact degree level match (Bachelor of Science); Moderate field relevance; Excellent grades (GPA: 3.8)',\n",
       "    'weight': 0.35},\n",
       "   'location': {'score': 100.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 1.0,\n",
       "    'explanation': 'No specific location requirements',\n",
       "    'weight': 0.3},\n",
       "   'experience': {'score': 12.402464065708417,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.12402464065708417,\n",
       "    'explanation': 'Relevant experience: 0.4 years; Required: 2.0-3.0 years; ⚠ 1.6 years short of minimum; Relevant roles: Machine Learning Engineer (Trainee) (0.87 similarity), AI Software Engineer (Intern) (0.53 similarity)',\n",
       "    'weight': 0.35},\n",
       "   'skills': {'score': 60.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.6,\n",
       "    'explanation': 'Skills matching not implemented yet',\n",
       "    'weight': 0.0},\n",
       "   'overall': {'score': 63.6741716859889,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.636741716859889,\n",
       "    'breakdown': {'education': {'score': 83.809455037117,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.8380945503711701,\n",
       "      'explanation': 'Exact degree level match (Bachelor of Science); Moderate field relevance; Excellent grades (GPA: 3.8)',\n",
       "      'weight': 0.35},\n",
       "     'location': {'score': 100.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 1.0,\n",
       "      'explanation': 'No specific location requirements',\n",
       "      'weight': 0.3},\n",
       "     'experience': {'score': 12.402464065708417,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.12402464065708417,\n",
       "      'explanation': 'Relevant experience: 0.4 years; Required: 2.0-3.0 years; ⚠ 1.6 years short of minimum; Relevant roles: Machine Learning Engineer (Trainee) (0.87 similarity), AI Software Engineer (Intern) (0.53 similarity)',\n",
       "      'weight': 0.35},\n",
       "     'skills': {'score': 60.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.6,\n",
       "      'explanation': 'Skills matching not implemented yet',\n",
       "      'weight': 0.0}}}},\n",
       "  'cover_message': '',\n",
       "  'weights_used': {'skills': 0.25,\n",
       "   'education': 0.15,\n",
       "   'experience_title': 0.2,\n",
       "   'experience_responsibilities': 0.2,\n",
       "   'experience_skills': 0.1,\n",
       "   'projects': 0.05,\n",
       "   'summary': 0.05}},\n",
       " {'applicant_name': 'Hilal Aziz',\n",
       "  'user_id': '683ee33e72bd949dd6fb102d',\n",
       "  'resume_id': '683eeba5be4f92cf16c108e8',\n",
       "  'application_id': '683eebb0be4f92cf16c108e9',\n",
       "  'applied_at': datetime.datetime(2025, 6, 3, 12, 33, 52, 435000),\n",
       "  'status': 'submitted',\n",
       "  'overall_score': 0.6831640244807551,\n",
       "  'section_scores': {'skills': 0.9258766,\n",
       "   'education': 0.8768468,\n",
       "   'experience_title': 0.86280715,\n",
       "   'experience_responsibilities': 0.87346196,\n",
       "   'experience_skills': 0.0,\n",
       "   'projects': 0.8832269,\n",
       "   'summary': 0.0},\n",
       "  'constraint_results': {'education': {'score': 70.809455037117,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.7080945503711701,\n",
       "    'explanation': 'Exact degree level match (Bachelor of Science in Artificial Intelligence); Moderate field relevance; No grade information',\n",
       "    'weight': 0.35},\n",
       "   'location': {'score': 100.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 1.0,\n",
       "    'explanation': 'No specific location requirements',\n",
       "    'weight': 0.3},\n",
       "   'experience': {'score': 8.131416837782341,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.0813141683778234,\n",
       "    'explanation': 'Relevant experience: 0.3 years; Required: 2.0-3.0 years; ⚠ 1.7 years short of minimum; Relevant roles: AI Software Engineer Intern (0.53 similarity)',\n",
       "    'weight': 0.35},\n",
       "   'skills': {'score': 60.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.6,\n",
       "    'explanation': 'Skills matching not implemented yet',\n",
       "    'weight': 0.0},\n",
       "   'overall': {'score': 57.62930515621477,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.5762930515621477,\n",
       "    'breakdown': {'education': {'score': 70.809455037117,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.7080945503711701,\n",
       "      'explanation': 'Exact degree level match (Bachelor of Science in Artificial Intelligence); Moderate field relevance; No grade information',\n",
       "      'weight': 0.35},\n",
       "     'location': {'score': 100.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 1.0,\n",
       "      'explanation': 'No specific location requirements',\n",
       "      'weight': 0.3},\n",
       "     'experience': {'score': 8.131416837782341,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.0813141683778234,\n",
       "      'explanation': 'Relevant experience: 0.3 years; Required: 2.0-3.0 years; ⚠ 1.7 years short of minimum; Relevant roles: AI Software Engineer Intern (0.53 similarity)',\n",
       "      'weight': 0.35},\n",
       "     'skills': {'score': 60.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.6,\n",
       "      'explanation': 'Skills matching not implemented yet',\n",
       "      'weight': 0.0}}}},\n",
       "  'cover_message': '',\n",
       "  'weights_used': {'skills': 0.25,\n",
       "   'education': 0.15,\n",
       "   'experience_title': 0.2,\n",
       "   'experience_responsibilities': 0.2,\n",
       "   'experience_skills': 0.1,\n",
       "   'projects': 0.05,\n",
       "   'summary': 0.05}},\n",
       " {'applicant_name': 'Zohaib Khan',\n",
       "  'user_id': '682399070434df6e65efbc4f',\n",
       "  'resume_id': '683eeafcbe4f92cf16c108e6',\n",
       "  'application_id': '683eeb05be4f92cf16c108e7',\n",
       "  'applied_at': datetime.datetime(2025, 6, 3, 12, 31, 1, 330000),\n",
       "  'status': 'submitted',\n",
       "  'overall_score': 0.6679330531311034,\n",
       "  'section_scores': {'skills': 0.90247434,\n",
       "   'education': 0.89879954,\n",
       "   'experience_title': 0.7520615,\n",
       "   'experience_responsibilities': 0.7584766,\n",
       "   'experience_skills': 0.0,\n",
       "   'projects': 0.7907511,\n",
       "   'summary': 0.0},\n",
       "  'constraint_results': {'education': {'score': 90.48774139881135,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.9048774139881135,\n",
       "    'explanation': \"Exact degree level match (Bachelor's); Good field relevance; Excellent grades (GPA: 3.8)\",\n",
       "    'weight': 0.35},\n",
       "   'location': {'score': 100.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 1.0,\n",
       "    'explanation': 'No specific location requirements',\n",
       "    'weight': 0.3},\n",
       "   'experience': {'score': 0.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.0,\n",
       "    'explanation': 'Relevant experience: 0.0 years; Required: 2.0-3.0 years; ⚠ 2.0 years short of minimum; No relevant experience found',\n",
       "    'weight': 0.35},\n",
       "   'skills': {'score': 60.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.6,\n",
       "    'explanation': 'Skills matching not implemented yet',\n",
       "    'weight': 0.0},\n",
       "   'overall': {'score': 61.67070948958398,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.6167070948958397,\n",
       "    'breakdown': {'education': {'score': 90.48774139881135,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.9048774139881135,\n",
       "      'explanation': \"Exact degree level match (Bachelor's); Good field relevance; Excellent grades (GPA: 3.8)\",\n",
       "      'weight': 0.35},\n",
       "     'location': {'score': 100.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 1.0,\n",
       "      'explanation': 'No specific location requirements',\n",
       "      'weight': 0.3},\n",
       "     'experience': {'score': 0.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.0,\n",
       "      'explanation': 'Relevant experience: 0.0 years; Required: 2.0-3.0 years; ⚠ 2.0 years short of minimum; No relevant experience found',\n",
       "      'weight': 0.35},\n",
       "     'skills': {'score': 60.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.6,\n",
       "      'explanation': 'Skills matching not implemented yet',\n",
       "      'weight': 0.0}}}},\n",
       "  'cover_message': '',\n",
       "  'weights_used': {'skills': 0.25,\n",
       "   'education': 0.15,\n",
       "   'experience_title': 0.2,\n",
       "   'experience_responsibilities': 0.2,\n",
       "   'experience_skills': 0.1,\n",
       "   'projects': 0.05,\n",
       "   'summary': 0.05}},\n",
       " {'applicant_name': 'Muneeb Ur Rehman',\n",
       "  'user_id': '6845b2f90a50408692826d01',\n",
       "  'resume_id': '6845b3120a50408692826d02',\n",
       "  'application_id': '6845b3660a50408692826d05',\n",
       "  'applied_at': datetime.datetime(2025, 6, 8, 15, 59, 34, 816000),\n",
       "  'status': 'submitted',\n",
       "  'overall_score': 0.6668285793066024,\n",
       "  'section_scores': {'skills': 0.91906625,\n",
       "   'education': 0.87796384,\n",
       "   'experience_title': 0.76838416,\n",
       "   'experience_responsibilities': 0.84172255,\n",
       "   'experience_skills': 0.0,\n",
       "   'projects': 0.88019514,\n",
       "   'summary': 0.0},\n",
       "  'constraint_results': {'education': {'score': 78.809455037117,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.78809455037117,\n",
       "    'explanation': 'Exact degree level match (Bachelor of Science); Moderate field relevance; Good grades (GPA: 3.3)',\n",
       "    'weight': 0.35},\n",
       "   'location': {'score': 100.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 1.0,\n",
       "    'explanation': 'No specific location requirements',\n",
       "    'weight': 0.3},\n",
       "   'experience': {'score': 0.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.0,\n",
       "    'explanation': 'Relevant experience: 0.0 years; Required: 2.0-3.0 years; ⚠ 2.0 years short of minimum; No relevant experience found',\n",
       "    'weight': 0.35},\n",
       "   'skills': {'score': 60.0,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.6,\n",
       "    'explanation': 'Skills matching not implemented yet',\n",
       "    'weight': 0.0},\n",
       "   'overall': {'score': 57.58330926299096,\n",
       "    'max_score': 100.0,\n",
       "    'normalized_score': 0.5758330926299096,\n",
       "    'breakdown': {'education': {'score': 78.809455037117,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.78809455037117,\n",
       "      'explanation': 'Exact degree level match (Bachelor of Science); Moderate field relevance; Good grades (GPA: 3.3)',\n",
       "      'weight': 0.35},\n",
       "     'location': {'score': 100.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 1.0,\n",
       "      'explanation': 'No specific location requirements',\n",
       "      'weight': 0.3},\n",
       "     'experience': {'score': 0.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.0,\n",
       "      'explanation': 'Relevant experience: 0.0 years; Required: 2.0-3.0 years; ⚠ 2.0 years short of minimum; No relevant experience found',\n",
       "      'weight': 0.35},\n",
       "     'skills': {'score': 60.0,\n",
       "      'max_score': 100.0,\n",
       "      'normalized_score': 0.6,\n",
       "      'explanation': 'Skills matching not implemented yet',\n",
       "      'weight': 0.0}}}},\n",
       "  'cover_message': '',\n",
       "  'weights_used': {'skills': 0.25,\n",
       "   'education': 0.15,\n",
       "   'experience_title': 0.2,\n",
       "   'experience_responsibilities': 0.2,\n",
       "   'experience_skills': 0.1,\n",
       "   'projects': 0.05,\n",
       "   'summary': 0.05}}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ali Suleman\n",
      "0.7693903880111981\n",
      "Hilal Aziz\n",
      "0.6831640244807551\n",
      "Zohaib Khan\n",
      "0.6679330531311034\n",
      "Muneeb Ur Rehman\n",
      "0.6668285793066024\n"
     ]
    }
   ],
   "source": [
    "for result in all_matches:\n",
    "    print(result['applicant_name'])\n",
    "    print(result['overall_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
